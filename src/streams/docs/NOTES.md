# Designing an event-driven Assessment Service

## Use case: generate assessment from xapi events

Once a class is finished, the assessment service is in charge of generating the assessments for all the students who participated in the class (aka room). 

Assessments are calculated using the xapi events that were generated by the students. It's essentially a big aggregation operation, where all the xapi events for a given room are retrieved, and then grouped and calculated for each user. The order of the events doesn't matter, but the room+user grouping is important. 

Currently, the assessments are generated on demand: when a teacher visits the assessments page for a given class for the first time, this fires a request to the CMS service, which then calls the Assessment service. The Assessment service then checks if it has calculated the scores for that room_id before, or if the number of attendees of that room has changed by making a request to the Attendance service. If either is true, then a recalculation of the scores is required. If not, the previously calculated scores are returned.

In essence, the assessment service is currently doing 2 things at once: it's an API service, but it also has a worker part, which fetches past events to calculate and store the scores. 

The fetching and aggregation process can take a few seconds. For relatively small classrooms and numbers of events, this so far has been proven to be good enough. However, a significant increase in requests can result in prolonged response times, which will be visible on the client side.

Moving the score calculation component out into its own worker process will have major benefits:
- scores can be calculated on a live or near-live basis
- scores will be pushed instead of being pulled upon request, this will faciliate report generation
- other event processing workers, such as ML scoring algorithms, can participate in the event-driven system, which the assessment worker would also be able to subscribe to


### Using Redis Streams as an alternative to Kafka 

Kafka is the goto large-scale stream processing framework. It allows for high-throughput and low-latency event handling. Other similar Open-Source technologies include Redpanda and RabbitMQ. Redis has been the industry standard key-value caching store for many years now. With the release of version 5 in 2018, it introduced a new datatype called Streams. 

Redis Streams offers a way of writing to and consuming from streams using Redis commands. All stream commands are prefixed with the letter `X`. To write to a stream use `XADD my_stream * [KEY] [VALUE]`. 

There are 2 ways of consuming from a Redis Stream. 
- You can use `XREAD COUNT [10] STREAMS my_stream [EVENT_ID]` to subscribe to all the events pushed to a given stream. This effectively amounts to fanning out the stream to multiple clients. 
- You can use Consumer Groups to have multiple workers consume different (and distinct) subsets of the same stream. 

[This article (Redis streams vs Kafka)](https://mattwestcott.org/blog/redis-streams-vs-kafka) describes the difference between how Redis and Kafka consumer groups work really well. 

The main takeaway from the above article is that Kafka and Redis consumer groups work very differently. 

- Kafka offers partitions, and a single partition is only ever processed by a single member of a Consumer Group. This provides an ordering guarantee.
- Redis doesn't offer partitions, and a consumer group is just a way of parallelizing the consumption of events coming from a single stream. It works more like a traditional job queue architecture, and thus loses the ordering guarantee.

Effectively, if you want to have a partition-based stream processing system on top of Redis Streams, you have to build it yourself, including:

- Event Partitioning, by creating a separate stream per partition
- Worker-partition assignment system to support multiple workers
- In-order processing with acknowledgement, which can be implemented using Redis stream commands that keep track of the offset 

### Architectures

#### 1. Single consumer

In this simple design, a single worker consumer all the events from a stream. 

➕ PROs:
- simple to implement
- no parallelization/concurrency to have to deal with
- sequential processing of all events
- live or near-live calculations

➖ CONs:
- not horizontally scalable

#### 2. Multiple workers in a consumer group

Multiple workers form a consumer group and process events based on their availability. There is no partition strategy.

➕ PROs:
- live or near-live calculations are possible
- can scale horizontally

➖ CONs:
- Database table locking required: since multiple workers could be processing events for the same room, database table locking will be required to prevent duplicate creation of room records, which are unique to each room. This delay wouldn't be significant to begin with, but will become more apparent if the number of workers increases significantly
- will require a more sophisticated implementation of the score calculation and caching of intermediate results to avoid wasteful computation

#### 3. Partitioning into multiple streams based on the room_id

Emulate the Kafka partition strategy by having one or multiple workers split up the events into multiple sub-streams. The partition is based on the room_id. 
Subsequently, a group of workers will then each have exclusive read access to each partition/sub-stream, which will ensure that all events for a given room will be consumed by the same worker, which will eliminate the need for table locking. 

➕ PROs:
- even more scalable
- no need for table locking

➖ CONs:
- more complex to implement
- workers need to aware of the existing partitions/sub-streams, this will require extra code to manage, which would inherently increases the chances for errors

#### 4. Partition based on Acknowledgement by members of the consumer group

Members of a consumer group will consume events coming from a single stream but will only process the ones that originate from a room_id that maps to a partition hash that was assigned to each worker and ignore the rest. Redis offers an `XACK` acknowledge command that will signal to the stream that said events have been consumed. 

➕ PROs:
- no need to split events into multiple streams
- no need to do database table locking
- horizontally scalable

➖ CONs:
- partition of events happens at the worker level
- the more workers and partitions there are, the more events will be have to filtered out by each worker, resulting in a lot of wasteful data transfer and computation. Thus, this isn't very scalable.
- acknowledge mechanism needs to be robust
- will likely require a backup worker that checks for unprocessed events

#### 5. Trigger the calculation with a separate stream

Instead of calculating scores for events as they come, either with a count-based or a time-based offset, the workers will subscribe to another stream that only captures events of beginning and end of a class. A worker will then pickup a class that has just ended and then read all the events for that class in the xapi stream. It will filter out all the events that are not for that class and do an acknolwledge. This will resolve the issue of having multiple workers processing events for the same class (no table locking required), and possibly reduce the total computation that needs to happen, as the aggregation process will take place more sporadically. 

➕ PROs:
- no table locking required
- calculation process happens less frequently
- reduced complexity compared to the previous examples
- fixed number of streams and no partitions required

➖ CONs:
- in the real world, a lot of classes will start and end at very similar times. This can result in episodic spikes in computation
- since Redis doesn't offer any kind of filtering or partitioning, each worker will have to read all the events that occured around the same time, which can originate from hundreds of classrooms, and then filter almost all of it out. This can result in a lot of data being read, only for a fraction of it to be actually consumed. Thus it isn't very scalable.


### Other considerations

When generating assessments, the service needs to request lesson material information from the CMS. Currently, these requests are authorized by verifying the access-token that was provided by the original request coming from the frontend client. In an event-driven design, requests can originate from the services themselves. The assessment service workers will need to generate their own authorization tokens using a shared key.

## Choice and discussion

I'm suggesting adopting an iterative approach and implement 1. as a proof concept and 2. for production. Having workers that don't depend on a partition strategy will make working with Redis much easier, since Redis doesn't support partitions out of the box. Ultimately, the usage of Redis Streams is meant as a stop-gap solution until we adopt a partition-based streaming teachnology such as Kafka. It thus seems appropriate to adopt the "less is more" approach and use the out-of-box APIs provided by Redis (even if they are limited) instead of building out a more complicated system around it. 

Another advantage of this approach: moving the workers over to Kafka or another partition-based streaming platform will be relatively straight forward, and will improve scalability by dropping the necessity in locking table access. 


## Sources

- [https://redis.io/topics/streams-intro]
- [https://mattwestcott.org/blog/redis-streams-vs-kafka]
- [https://javascript.plainenglish.io/an-introduction-to-redis-stream-57445a21751e]
- [https://github.com/xolvio/typescript-event-sourcing]
- [https://gist.github.com/nicolashery/da9c101891ca0c9f9ceb]
