# RFC-045 - Event-Driven Assessments

## Synopsis

As Kidsloop scales and ventures into the event-driven world, the assessment service needs to be split into its 2 composing parts: the API and the worker. This separation into 2 components will allow each one to be improved individually, with the API no longer having to do lengthy computations and thus risking slow request times (up to 3-4 seconds in some situations) and improve both the API and the worker's capacity to reliably scale and interact with other services.

## Background

Once a class is finished, the assessment service is in charge of generating the assessments for all the students who participated in the class (aka room). 

Assessments are calculated using the xapi events that were generated by the students. It's essentially a big aggregation operation, where all the xapi events for a given room are retrieved, and then grouped and calculated for each user. The order of the events doesn't matter, but the room+user grouping is important. 

Currently, the assessments are generated on demand: when a teacher visits the assessments page for a given class for the first time, this fires a request to the CMS service, which then calls the Assessment service. The Assessment service then checks if it has calculated the scores for that room_id before, or if the number of attendees of that room has changed by making a request to the Attendance service. If either is true, then a recalculation of the scores is required. If not, the already calculated scores are returned.

In essence, the assessment service is currently doing 2 things at once: it's an API service, but it also has a worker part, which fetches past xapi events and then based on them calculates and stores the scores. 

The fetching and aggregation process can take up to a few seconds. For relatively small classrooms and number of events, this so far has been proven to be good enough. However, a significant increase in requests or total number of events that need to fetched and processed for each class can result in prolonged response times, which will be visible on the client side.

Moving the score calculation component out into its own worker process will have major benefits:
- the worker will be able to process events on a live or near-live basis, instead of waiting of a request to come in
- the API service will be able to have faster and more reliable response times
- scores will be pushed instead of being pulled upon request, this will faciliate report generation and other future events
- other event processing workers, such as the upcoming ML scoring algorithms, can participate in the event-driven system and push more events to the stream to which the assessment worker would be able to subscribe to


## Analysis

> *Pick the ones that fits best 
> For discovery ticket, describe what was explored and what was discovered. Draw conclusions and document the possible next steps.
> When documenting a workflow, include graphs / charts that visualise the textual description.
> When suggesting a new design, revisit the RFC when the decision for a specific design approach has been made. 

### Using Redis Streams as a stop-gap alternative to Kafka 

Kafka is the goto large-scale stream processing framework. It allows for high-throughput and low-latency event handling. Other similar Open-Source technologies include Redpanda and RabbitMQ. Redis has been the industry standard key-value caching store for many years now. With the release of version 5 in 2018, it introduced a new datatype called Streams. The architecture team is currently in the process of deciding which streaming platform to use, and while that's happening we can use Redis to bridge the gap and allow development to proceed. 

Redis Streams offers a way of writing to and consuming from streams using Redis commands. All stream commands are prefixed with the letter `X`. To write to a stream use `XADD my_stream * [KEY] [VALUE]`. 

There are 2 ways of consuming from a Redis Stream. 
- You can use `XREAD COUNT [10] STREAMS my_stream [EVENT_ID]` to subscribe to all the events pushed to a given stream. This effectively amounts to fanning out the stream to multiple clients. 
- You can use Consumer Groups to have multiple workers consume different (and distinct) subsets of the same stream. 

[This article (Redis streams vs Kafka)](https://mattwestcott.org/blog/redis-streams-vs-kafka) describes the difference between how Redis and Kafka consumer groups work really well. 

The main takeaway from the above article is that Kafka and Redis consumer groups work very differently. 

- Kafka offers partitions, and a single partition is only ever processed by a single member of a Consumer Group. This provides an ordering guarantee.
- Redis doesn't offer partitions, and a consumer group is just a way of parallelizing the consumption of events coming from a single stream. It works more like a traditional job queue architecture, and thus loses the ordering guarantee.

Effectively, if you want to have a partition-based stream processing system on top of Redis Streams, you have to build it yourself, including:

- Event Partitioning, by creating a separate stream per partition
- Worker-partition assignment system to support multiple workers
- In-order processing with acknowledgement, which can be implemented using Redis stream commands that keep track of the offset 

## Analysis: Architectures

Given these differences, here are a few designs that have been explored to satisfy the needs for the assessment generation workflow:
- xapi events need to be grouped by room and by user
- the order of the events doesn't matter, but their consistency needs to be guaranteed for accurate scores

### 1. Single consumer

In this simple design, a single worker consumer all the events from a stream. 

➕ PROs:
- simple to implement
- no parallelization/concurrency to have to deal with
- sequential processing of all events
- live or near-live calculations

➖ CONs:
- not horizontally scalable

### 2. Multiple workers in a consumer group

Multiple workers form a consumer group and process events based on their availability. There is no partition strategy.

➕ PROs:
- live or near-live calculations are possible
- can scale horizontally

➖ CONs:
- Database table locking required: since multiple workers could be processing events for the same room, database table locking will be required to prevent duplicate creation of room records, which are unique to each room. This delay wouldn't be significant to begin with, but will become more apparent if the number of workers increases significantly
- will require a more sophisticated implementation of the score calculation and caching of intermediate results to avoid wasteful computation

### 3. Partitioning into multiple streams based on the room_id

Emulate the Kafka partition strategy by having one or multiple workers split up the events into multiple sub-streams. The partition is based on the room_id. 
Subsequently, a group of workers will then each have exclusive read access to each partition/sub-stream, which will ensure that all events for a given room will be consumed by the same worker, which will eliminate the need for table locking. 

➕ PROs:
- even more scalable
- no need for table locking

➖ CONs:
- more complex to implement
- workers need to aware of the existing partitions/sub-streams, this will require extra code to manage, which would inherently increases the chances for errors

### 4. Partition based on Acknowledgement by members of the consumer group

Members of a consumer group will consume events coming from a single stream but will only process the ones that originate from a room_id that maps to a partition hash that was assigned to each worker and ignore the rest. Redis offers an `XACK` acknowledge command that will signal to the stream that said events have been consumed. 

➕ PROs:
- no need to split events into multiple streams
- no need to do database table locking
- horizontally scalable

➖ CONs:
- partition of events happens at the worker level
- the more workers and partitions there are, the more events will be have to filtered out by each worker, resulting in a lot of wasteful data transfer and computation. Thus, this isn't very scalable.
- acknowledge mechanism needs to be robust
- will likely require a backup worker that checks for unprocessed events

### 5. Trigger the calculation with a separate stream

Instead of calculating scores for events as they come, either with a count-based or a time-based offset, the workers will subscribe to another stream that only captures events of beginning and end of a class. A worker will then pickup a class that has just ended and then read all the events for that class in the xapi stream. It will filter out all the events that are not for that class and do an acknolwledge. This will resolve the issue of having multiple workers processing events for the same class (no table locking required), and possibly reduce the total computation that needs to happen, as the aggregation process will take place more sporadically. 

➕ PROs:
- no table locking required
- calculation process happens less frequently
- reduced complexity compared to the previous examples
- fixed number of streams and no partitions required

➖ CONs:
- in the real world, a lot of classes will start and end at very similar times. This can result in episodic spikes in computation
- since Redis doesn't offer any kind of filtering or partitioning, each worker will have to read all the events that occured around the same time, which can originate from hundreds of classrooms, and then filter almost all of it out. This can result in a lot of data being read, only for a fraction of it to be actually consumed. Thus it isn't very scalable.


### Other considerations

When generating assessments, the service needs to request lesson material information from the CMS. Currently, these requests are authorized by verifying the access-token that was provided by the original request coming from the frontend client. In an event-driven design, requests can originate from the services themselves. The assessment service workers will need to generate their own authorization tokens using a shared key.


## Implementation

After careful consideration, I suggest adopting an iterative approach and implement 1. as a proof concept and 2. for production. Having workers that don't depend on a partition strategy will make working with Redis much easier, since Redis doesn't support partitions out of the box. Ultimately, the usage of Redis Streams is meant as a stop-gap solution until we adopt a partition-based streaming teachnology such as Kafka. It thus seems appropriate to adopt the "less is more" approach and use the out-of-box APIs provided by Redis (even if they are limited) instead of building out a more complicated system around it. 

The only real limitation of 2. is the necessity for locking Room table access. But given our current and expected scale in the coming 3-4 months, this shouldn't be a problem even with dozens of workers. I expect this to start having a significant impact once we start having hundreds of workers trying to access the same table.

Another advantage of this approach: moving the workers over to Kafka or another partition-based streaming platform will be relatively straight forward, and will improve scalability by dropping the necessity in locking table access. 

## Appendix

- [https://redis.io/topics/streams-intro]
- [https://mattwestcott.org/blog/redis-streams-vs-kafka]
- [https://javascript.plainenglish.io/an-introduction-to-redis-stream-57445a21751e]
- [https://github.com/xolvio/typescript-event-sourcing]
- [https://gist.github.com/nicolashery/da9c101891ca0c9f9ceb]


## Decision

### Status: 

[pending]

### People involved:

Colt
Owen
Enrique
Jean
Mitch
Chris Pedder
Manuel
Herry

